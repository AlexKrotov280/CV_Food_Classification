{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as img\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#print(tf.VERSION)\n",
    "#from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to the model was trained on differen resourses such as Colab etc. It was necessary to zip/unzip data\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = 'train.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('train')\n",
    "local_zip = 'test.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('test')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 32 classes.\n",
      "Found 8000 images belonging to 32 classes.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "nb_train_samples = 750 \n",
    "nb_validation_samples = 250 \n",
    "batch_size = 32\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=30, # 6-th from 25 to 30\n",
    "    zoom_range=0.5, # 7-th from 0.3 to 0.5\n",
    "    fill_mode='constant',\n",
    "    rotation_range=180, #6-rd itteration from 90 to 180\n",
    "    width_shift_range=.25, # 5-th from 0.5 to 0.25\n",
    "    height_shift_range=.25, # 5-th from 0.5 to 0.25\n",
    "    horizontal_flip=True)\n",
    "    #vertical_flip=True,\n",
    "    #channel_shift_range=100., 3-rd itteration\n",
    "    #brightness_range=[0.5,1.0], 6-th \n",
    "    #zca_whitening=True) # 6-th\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train/train/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x150\n",
    "        batch_size = batch_size,\n",
    "        # Since we use 32 classes, we need class_mode='categorical'\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'test/test/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size = batch_size,\n",
    "        # Since we use 32 classes, we need class_mode='categorical'\n",
    "        class_mode='categorical')\n",
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "# Frozing the model layers. For our case it's not working\n",
    "#for layer in inception.layers:\n",
    "#  layer.trainable = False\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x) # 7-th \n",
    "\n",
    "predictions = Dense(32,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "model = Model(inputs=inception.input, outputs=predictions)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.001, momentum=0.9), metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='best_model_44class.hdf5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('history_44class.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = nb_train_samples // batch_size,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps = nb_validation_samples // batch_size,  \n",
    "      epochs=150,\n",
    "      verbose=1\n",
    "     #callbacks=[csv_logger, checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    plt.show()\n",
    "def plot_loss(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()\n",
    "plot_accuracy(history,'FOOD101_32 classes')\n",
    "plot_loss(history,'FOOD101_32 classes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
